# embedding_compare

# TÃ¼rkÃ§e TÄ±bbi Metinler Ä°Ã§in En Ä°yi Embedding Modeli Hangisi?

## 3 popÃ¼ler modeli MedTurkQuaD veri setiyle test ettim. En hÄ±zlÄ± model her zaman en iyi deÄŸilmiÅŸ â€” iÅŸte kanÄ±tÄ±.

---

![Embedding Models Comparison](https://via.placeholder.com/1200x400/1a1a1a/ffffff?text=Embedding+Models+Comparison)

---

**â±ï¸ Okuma SÃ¼resi:** 10 dakika | **ğŸ”§ Seviye:** Orta | **ğŸ’» Kod:** Dahil  
**ğŸ‘¤ Yazar:** [Ä°sminiz] | **ğŸ“… Tarih:** [Tarih]

---

## ğŸ“Œ TL;DR (HÄ±zlÄ± Ã–zet)

> 3 popÃ¼ler embedding modelini (Multi-MiniLM, BGE-M3, all-mpnet) TÃ¼rkÃ§e tÄ±bbi soru-cevap veri setiyle karÅŸÄ±laÅŸtÄ±rdÄ±m. **SonuÃ§lar ÅŸaÅŸÄ±rtÄ±cÄ±:**
> 
> - ğŸ† **BGE-M3:** En iyi retrieval (MRR: 0.0338) ama en yavaÅŸ (50.59 sn)
> - âš¡ **Multi-MiniLM:** En hÄ±zlÄ± (15.81 sn) ve TÃ¼rkÃ§e morfolojisinde ÅŸampiyon (0.9284)
> - ğŸš« **all-mpnet:** Ä°ngilizce'de harika ama TÃ¼rkÃ§e'de fiyasko (MRR: 0.0084)
> 
> **Ana ders:** "Multilingual" etiketi yeterli deÄŸil. Domain-specific test ÅŸart!

---

## ğŸ­ Hikaye: Neden Bu Teste Ä°htiyacÄ±m Oldu?

GeÃ§en ay bir tÄ±bbi soru-cevap sistemi geliÅŸtiriyordum. HuggingFace'te en popÃ¼ler embedding modellerini denedim. SonuÃ§lar... felaketti.

"Apse nedir?" sorusuna sistem "akciÄŸer kanseri" cevabÄ±nÄ± veriyordu. Modeli deÄŸiÅŸtirdim, biraz daha iyi oldu ama yine de tatmin edici deÄŸildi. 

O zaman ÅŸunu anladÄ±m: **Benchmark tablolarÄ± Ä°ngilizce iÃ§in geÃ§erli. TÃ¼rkÃ§e + TÄ±p kombinasyonu iÃ§in hiÃ§bir veri yoktu.**

Bu yazÄ±da, **sistematik bir karÅŸÄ±laÅŸtÄ±rma** yaparak hangi modelin gerÃ§ekten iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶stereceÄŸim.

---

## ğŸ¯ Bu KarÅŸÄ±laÅŸtÄ±rma Neden Ã–nemli?

### Embedding Modeli SeÃ§erken YaÅŸanan Tipik Sorunlar

âŒ **"En popÃ¼ler modeli seÃ§eyim"** â†’ PopÃ¼lerlik â‰  Senin use case'in iÃ§in uygun  
âŒ **"Multilingual yazÄ±yor, TÃ¼rkÃ§e destekler"** â†’ Teoride evet, pratikte bazen hayÄ±r  
âŒ **"Benchmark'ta 1. sÄ±rada"** â†’ Hangi dilde? Hangi domain'de?  
âŒ **"En bÃ¼yÃ¼k model en iyisidir"** â†’ Daha yavaÅŸ, daha pahalÄ±, her zaman daha iyi deÄŸil

### Bu Testin FarkÄ±

âœ… **AynÄ± veri seti** â†’ Adil karÅŸÄ±laÅŸtÄ±rma  
âœ… **AynÄ± metrikler** â†’ Objektif deÄŸerlendirme  
âœ… **Tekrarlanabilir kod** â†’ Sen de deneyebilirsin  
âœ… **TÃ¼rkÃ§e + Domain-specific** â†’ GerÃ§ek dÃ¼nya senaryosu

---

## ğŸ”¬ Test DÃ¼zeneÄŸi

### YarÄ±ÅŸmaya KatÄ±lan Modeller

| Model | Boyut | Ã–zellik | Beklenti |
|-------|-------|---------|----------|
| **Multi-MiniLM-L12-v2** | 384 | Hafif, Ã§ok dilli | HÄ±zlÄ± ama yeterli mi? |
| **BGE-M3** | 1024 | Yeni nesil, gÃ¼Ã§lÃ¼ | En iyi ama ne kadar yavaÅŸ? |
| **all-mpnet-base-v2** | 768 | Ä°ngilizce SOTA | TÃ¼rkÃ§e'de ne olacak? |

### Test ArenasÄ±: MedTurkQuaD Veri Seti

**Ne?** TÃ¼rkÃ§e tÄ±bbi soru-cevap veri seti  
**Neden zor?** Ä°ki katmanlÄ± zorluk:
1. ğŸ‡¹ğŸ‡· **TÃ¼rkÃ§e morfolojisi** (ekler, Ã§ekim)
2. ğŸ¥ **TÄ±bbi terminoloji** (domain-specific)

**Ã–rnek Zorluk:**

```
Soru: "Apse genellikle neyin neden olduÄŸu bir yangÄ± tÃ¼rÃ¼dÃ¼r?"

âœ… DoÄŸru: "piyojen bakterilerin"
âŒ YanÄ±ltÄ±cÄ± Negatif: "akciÄŸer dokularÄ±ndaki hÃ¼crelerin kontrolsÃ¼z..."

â†’ Her iki cevap da tÄ±bbi terim iÃ§eriyor!
â†’ Model ince ayrÄ±mlarÄ± yakalayabilmeli
```

### Tekrarlanabilirlik Garantisi

```python
# Her Ã§alÄ±ÅŸtÄ±rmada aynÄ± sonuÃ§
device = "cuda" if torch.cuda.is_available() else "cpu"
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)
```

**Neden 42?** Evrenin, yaÅŸamÄ±n ve her ÅŸeyin cevabÄ± ğŸ˜‰ (ve AI topluluÄŸunun standart seed'i)

---

## ğŸ“Š Test SÃ¼reci: AdÄ±m AdÄ±m

### AdÄ±m 1: Veri HazÄ±rlÄ±ÄŸÄ± - Negative Sampling

```python
def process_qa_data(qa_data):
    all_queries, all_positives, all_negatives = [], [], []
    
    # Sorular ve doÄŸru cevaplar
    for doc in qa_data.get('data', []):
        for paragraph in doc.get('paragraphs', []):
            for qa_pair in paragraph.get('qas', []):
                all_queries.append(qa_pair['question'])
                all_positives.append(qa_pair['answers'][0]['text'])
    
    # Her pozitif iÃ§in rastgele bir negative
    num_pairs = len(all_positives)
    for i in range(num_pairs):
        idx = i
        while idx == i:  # AynÄ± cevabÄ± alma
            idx = random.choice(range(num_pairs))
        all_negatives.append(all_positives[idx])
    
    return all_queries, all_positives, all_negatives
```

**Neden bu yÃ¶ntem?**
- GerÃ§ek dÃ¼nyada da doÄŸru cevap yanlÄ±ÅŸlar arasÄ±nda kaybolur
- Modelin ayÄ±rt etme yeteneÄŸini test eder
- Retrieval sistemleri iÃ§in klasik benchmark yÃ¶ntemi

### AdÄ±m 2: Embedding Ãœretimi ve SÃ¼re Ã–lÃ§Ã¼mÃ¼

```python
for model_name, model in models_to_test.items():
    start_time = time.time()
    
    # Encode et
    query_vectors = model.encode(queries, convert_to_numpy=True, show_progress_bar=True)
    doc_vectors = model.encode(documents, convert_to_numpy=True, show_progress_bar=True)
    
    duration = time.time() - start_time
    print(f"â±ï¸ {model_name}: {duration:.2f} saniye")
```

**Ã‡Ä±ktÄ±:**
```
â±ï¸ Multi-MiniLM-L12-v2: 15.81 saniye
â±ï¸ BGE-M3: 50.59 saniye
â±ï¸ all-mpnet-base-v2: 25.00 saniye
```

### AdÄ±m 3: FAISS ile Similarity Search

**Kritik Detay:** L2 Normalizasyon

```python
dim = query_vectors.shape[1]
index = faiss.IndexFlatIP(dim)  # Inner Product Index

# ğŸ”‘ Normalizasyon = Cosine Similarity
faiss.normalize_L2(doc_vectors)
faiss.normalize_L2(query_vectors)

index.add(doc_vectors)
D, I = index.search(query_vectors, k=len(documents))
```

**Neden normalize?**

| Durum | FormÃ¼l | Ne Ã¶lÃ§er? |
|-------|--------|-----------|
| Normalizasyon yok | `IP(A,B) = \|A\| Ã— \|B\| Ã— cos(Î¸)` | BÃ¼yÃ¼klÃ¼k + AÃ§Ä± |
| Normalizasyon var | `IP(A,B) = cos(Î¸)` | Sadece AÃ§Ä± (semantik) |

---

## ğŸ“ˆ DeÄŸerlendirme: 4 FarklÄ± Metrik

### 1ï¸âƒ£ MRR (Mean Reciprocal Rank)

**Ne Ã¶lÃ§er?** DoÄŸru cevap ortalama kaÃ§Ä±ncÄ± sÄ±rada?

```python
def compute_mrr(search_results, true_indices):
    rr_sum = 0
    for i in range(len(true_indices)):
        ranks = np.where(search_results[i] == true_indices[i])[0]
        if len(ranks) > 0:
            rr_sum += 1 / (ranks[0] + 1)
    return rr_sum / len(true_indices)
```

**Yorumlama:**
- MRR = 1.0 â†’ Her soru iÃ§in doÄŸru cevap 1. sÄ±rada (mÃ¼kemmel!)
- MRR = 0.5 â†’ Ortalama 2. sÄ±rada
- MRR = 0.033 â†’ Ortalama ~30. sÄ±rada (dÃ¼ÅŸÃ¼k)

### 2ï¸âƒ£ Recall@K

**Ne Ã¶lÃ§er?** Ä°lk K sonuÃ§ta doÄŸru cevap var mÄ±?

| Metrik | AÃ§Ä±klama |
|--------|----------|
| Recall@1 | Ä°lk sonuÃ§ doÄŸru mu? (en sÄ±kÄ± test) |
| Recall@3 | Ä°lk 3'te var mÄ±? |
| Recall@10 | Ä°lk 10'da var mÄ±? |

**Neden Ã¶nemli?**
- Recall@1 â†’ KullanÄ±cÄ±ya tek sonuÃ§ gÃ¶steriyorsanÄ±z
- Recall@10 â†’ Liste halinde gÃ¶steriyorsanÄ±z

### 3ï¸âƒ£ Morphology Score

**Ne Ã¶lÃ§er?** TÃ¼rkÃ§e eklere duyarlÄ±lÄ±k

**Test Ã§iftleri:**
```python
morph_pairs = [
    ("geliyorum", "gelmekteyim"),
    ("gidecek", "gider"),
    ("yaptÄ±m", "yapÄ±yorum"),
    ("okuyor", "okumakta"),
    ("koÅŸacaÄŸÄ±m", "koÅŸarÄ±m"),
    ("araba", "arabalar"),
    ("evdeyim", "evde olmak")
]
```

**Hesaplama:**
```python
# Her Ã§iftin cosine benzerliÄŸini hesapla
similarities = []
for pair in morph_pairs:
    vec1 = model.encode(pair[0])
    vec2 = model.encode(pair[1])
    sim = cosine_similarity([vec1], [vec2])[0][0]
    similarities.append(sim)

morph_score = np.mean(similarities)
```

**Yorumlama:**
- Skor > 0.9 â†’ MÃ¼kemmel TÃ¼rkÃ§e anlayÄ±ÅŸÄ±
- Skor 0.7-0.9 â†’ Ä°yi
- Skor < 0.7 â†’ ZayÄ±f (her eki farklÄ± kelime olarak gÃ¶rÃ¼yor)

### 4ï¸âƒ£ Silhouette Score

**Ne Ã¶lÃ§er?** Embedding uzayÄ± ne kadar dÃ¼zenli?

```python
kmeans = KMeans(n_clusters=2, random_state=42, n_init='auto')
labels = kmeans.fit_predict(doc_vectors)
sil_score = silhouette_score(doc_vectors, labels)
```

**Yorumlama:**
- +1'e yakÄ±n â†’ KÃ¼meler Ã§ok iyi ayrÄ±ÅŸmÄ±ÅŸ
- 0'a yakÄ±n â†’ KÃ¼meler iÃ§ iÃ§e
- -1'e yakÄ±n â†’ YanlÄ±ÅŸ kÃ¼melenmiÅŸ

---

## ğŸ† SonuÃ§lar: Åampiyonlar ve SÃ¼rprizler

### ğŸ“Š Tam SonuÃ§ Tablosu

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model               â”‚ Boyutâ”‚ SÃ¼re (sn)â”‚ Silhouette â”‚ Morph Score â”‚  MRR   â”‚ Recall@1 â”‚ Recall@3 â”‚ Recall@5 â”‚ Recall@10 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BGE-M3              â”‚ 1024 â”‚  50.59   â”‚   0.0366   â”‚   0.8113    â”‚ 0.0338 â”‚  1.12%   â”‚  3.24%   â”‚  4.91%   â”‚   7.66%   â”‚
â”‚ Multi-MiniLM-L12-v2 â”‚  384 â”‚  15.81   â”‚   0.0758   â”‚   0.9284    â”‚ 0.0200 â”‚  0.70%   â”‚  1.93%   â”‚  2.72%   â”‚   4.34%   â”‚
â”‚ all-mpnet-base-v2   â”‚  768 â”‚  25.00   â”‚   0.1185   â”‚   0.7460    â”‚ 0.0084 â”‚  0.30%   â”‚  0.78%   â”‚  1.29%   â”‚   1.85%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸª GÃ¶rsel Analiz

#### 1. Performans Metrikleri (2Ã—2 GÃ¶rsel)

![Performans Raporu](performans_metrikleri_raporu.png)

**Ne gÃ¶rÃ¼yoruz?**
- **MRR grafiÄŸi:** TÃ¼m barlar kÄ±sa (dÃ¼ÅŸÃ¼k deÄŸerler) â†’ Domain Ã§ok zor
- **Recall@1 grafiÄŸi:** BGE-M3 aÃ§Ä±k ara Ã¶nde ama yine de dÃ¼ÅŸÃ¼k
- **Morph Score grafiÄŸi:** Multi-MiniLM ÅŸampiyon ğŸ†
- **Silhouette grafiÄŸi:** all-mpnet birinci ama bu yanÄ±ltÄ±cÄ±

#### 2. HÄ±z vs Kalite Trade-off (Scatter Plot)

![HÄ±z vs Kalite](performans_vs_hiz.png)

**Analiz:**
- **Sol Ã¼st = Ä°deal bÃ¶lge** (hÄ±zlÄ± + kaliteli)
- **BGE-M3:** SaÄŸ Ã¼stte (yavaÅŸ ama kaliteli)
- **Multi-MiniLM:** Sol altta (hÄ±zlÄ± ama MRR orta)
- **all-mpnet:** Ortada kaybolmuÅŸ (ne hÄ±zlÄ± ne kaliteli)

**Karar rehberi:**
- Real-time sistem â†’ Multi-MiniLM
- Offline batch â†’ BGE-M3

#### 3. Radar Chart: Model Profilleri

![Radar Profil](modellerin_radar_profili.png)

**Karakter analizi:**

ğŸ”µ **BGE-M3:** "YavaÅŸ ama Etkili"
- MRR yÃ¼ksek, speed dÃ¼ÅŸÃ¼k
- BÃ¼yÃ¼k projelerde batch iÅŸleme iÃ§in ideal

ğŸŸ¢ **Multi-MiniLM:** "HÄ±zlÄ± ve TÃ¼rkÃ§e'ye Ã–zel"
- Speed ve morph score yÃ¼ksek
- Real-time uygulamalar iÃ§in mÃ¼kemmel

ğŸ”´ **all-mpnet:** "DÃ¼zenli ama YanlÄ±ÅŸ"
- Sadece silhouette iyi
- TÃ¼rkÃ§e iÃ§in kullanmayÄ±n

---

## ğŸ’¥ ÅaÅŸÄ±rtÄ±cÄ± Bulgular ve Analizler

### ğŸš¨ Bulgu 1: MRR DeÄŸerleri Neden Bu Kadar DÃ¼ÅŸÃ¼k?

**Beklenti:** MRR > 0.5 (doÄŸru cevap ilk 2'de)  
**GerÃ§ek:** MRR = 0.008-0.033 (doÄŸru cevap 30-120. sÄ±rada)

**3 Neden:**

1. **Domain Gap (Domain BoÅŸluÄŸu)**
   - Modeller Wikipedia, kitaplar, haberlerle eÄŸitilmiÅŸ
   - TÄ±bbi terminoloji eÄŸitim verisinin %1'inden azÄ±
   - "Piyojen bakteriler" gibi terimler nadiren gÃ¶rÃ¼lÃ¼yor

2. **Negative Sampling ZorluÄŸu**
   - Rastgele seÃ§ilen "yanlÄ±ÅŸ" cevaplar aslÄ±nda ilgili
   - Her ikisi de tÄ±bbi terim â†’ Model karÄ±ÅŸtÄ±rÄ±yor
   - GerÃ§ek dÃ¼nya senaryosuna Ã§ok benzer (iyi bir test!)

3. **Fine-tuning EksikliÄŸi**
   - Genel amaÃ§lÄ± modeller spesifik domain'de zayÄ±f
   - Fine-tuning ile 5-10x iyileÅŸme beklenebilir

> **ğŸ’¡ Pratik ders:** MRR < 0.1 gÃ¶rÃ¼rseniz panik yapmayÄ±n. Domain-specific veri setleri iÃ§in normal. Fine-tuning ÅŸart!

### ğŸ­ Bulgu 2: Morfoloji Åampiyonu â‰  Retrieval Åampiyonu

| Model | Morph Score | MRR | Ä°liÅŸki |
|-------|-------------|-----|--------|
| Multi-MiniLM | ğŸ¥‡ 0.9284 | ğŸ¥ˆ 0.0200 | Ters korelasyon! |
| BGE-M3 | ğŸ¥ˆ 0.8113 | ğŸ¥‡ 0.0338 | |

**Neden bÃ¶yle?**

**Morfoloji iÃ§in gerekli:**
- Surface-level benzerlik ("geliyorum" â‰ˆ "gelmekteyim")
- Dil bilgisi kurallarÄ±
- Syntax patterns

**Retrieval iÃ§in gerekli:**
- Deep semantic understanding
- Context awareness
- Domain knowledge

**Analoji:**
> Morfoloji = Kelimelerin **ÅŸeklini** tanÄ±mak  
> Retrieval = Kelimelerin **anlamÄ±nÄ±** kavramak

### ğŸ‡¬ğŸ‡§ Bulgu 3: Ä°ngilizce Modelinin TÃ¼rkÃ§e Fiyaskosu

**all-mpnet-base-v2 rapor kartÄ±:**
- âŒ MRR: 0.0084 (son sÄ±ra)
- âŒ Morph: 0.7460 (son sÄ±ra)
- âŒ Recall@1: 0.30% (son sÄ±ra)
- âœ… Silhouette: 0.1185 (1. sÄ±ra) ğŸ¤”

**Neden silhouette yÃ¼ksek ama diÄŸerleri dÃ¼ÅŸÃ¼k?**

Silhouette "dÃ¼zenlilik" Ã¶lÃ§er, "doÄŸruluk" deÄŸil. Model vektÃ¶rleri gÃ¼zel organize etmiÅŸ ama **yanlÄ±ÅŸ organize etmiÅŸ**.

**Analoji:**
> KitaplarÄ± renklerine gÃ¶re dÃ¼zenlemiÅŸsiniz (iyi organize)  
> Ama konularÄ±na gÃ¶re arayanlar bulamÄ±yor (yanlÄ±ÅŸ organize)

**Ders:** Tek metriÄŸe gÃ¼venmeyin!

### âš¡ Bulgu 4: HÄ±z FarkÄ± Dramatik

| Model | SÃ¼re | Multi-MiniLM'e gÃ¶re |
|-------|------|---------------------|
| Multi-MiniLM | 15.81 sn | 1.0x (referans) |
| all-mpnet | 25.00 sn | 1.6x daha yavaÅŸ |
| BGE-M3 | 50.59 sn | **3.2x daha yavaÅŸ** |

**GerÃ§ek dÃ¼nya etkisi:**

Senaryoya gÃ¶re 1000 sorgu iÅŸleme sÃ¼resi:
- Multi-MiniLM: ~4.4 saat
- all-mpnet: ~7 saat
- BGE-M3: ~14 saat

**Real-time sistemde:**
- KullanÄ±cÄ± baÅŸÄ±na 50ms vs 160ms fark yaratÄ±r
- 100 eÅŸzamanlÄ± kullanÄ±cÄ± = sunucu terkar

---

## ğŸ¯ Karar Rehberi: Hangi Modeli SeÃ§meliyim?

### ğŸ“‹ Senaryo BazlÄ± Ã–neriler

#### Senaryo 1: MÃ¼ÅŸteri Destek Chatbot (Real-time)

**Gereksinimler:**
- âš¡ HÄ±z kritik (kullanÄ±cÄ± beklemez)
- ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e morfoloji Ã¶nemli (kullanÄ±cÄ±lar farklÄ± yazÄ±yor)
- ğŸ“Š Yeterli doÄŸruluk (mÃ¼kemmel olmasÄ±na gerek yok)

**SeÃ§im:** âœ… **Multi-MiniLM-L12-v2**

**Neden:**
- 3.2x daha hÄ±zlÄ± (BGE-M3'e gÃ¶re)
- Morfoloji ÅŸampiyonu (0.9284)
- MRR yeterli (0.0200)
- KÃ¼Ã§Ã¼k vektÃ¶r = az RAM

**Ã–rnek implementasyon:**
```python
from sentence_transformers import SentenceTransformer
import faiss

model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

# KB'deki tÃ¼m cevaplarÄ± encode et (offline)
kb_answers = ["cevap1", "cevap2", ...]
answer_vectors = model.encode(kb_answers)

# FAISS index oluÅŸtur
index = faiss.IndexFlatIP(384)
faiss.normalize_L2(answer_vectors)
index.add(answer_vectors)

# KullanÄ±cÄ± sorusu geldiÄŸinde (online)
def get_answer(user_question):
    q_vec = model.encode([user_question])
    faiss.normalize_L2(q_vec)
    D, I = index.search(q_vec, k=3)
    return [kb_answers[i] for i in I[0]]
```

#### Senaryo 2: TÄ±bbi DokÃ¼man Arama Motoru (Offline)

**Gereksinimler:**
- ğŸ¯ Kalite kritik (yanlÄ±ÅŸ sonuÃ§ kritik hata)
- â³ HÄ±z ikincil (batch iÅŸlem)
- ğŸ¥ Domain Ã§ok spesifik

**SeÃ§im:** âœ… **BGE-M3 + Fine-tuning**

**Neden:**
- En iyi MRR (0.0338)
- BÃ¼yÃ¼k model = daha fazla kapÃ¼asite
- HÄ±z batch iÅŸlemde Ã¶nemsiz

**Fine-tuning Ã¶rneÄŸi:**
```python
from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader

# Model yÃ¼kle
model = SentenceTransformer('BAAI/bge-m3')

# TÄ±bbi soru-cevap Ã§iftlerini hazÄ±rla
train_examples = [
    InputExample(texts=['Apse nedir?', 'piyojen bakterilerin neden olduÄŸu yangÄ±']),
    InputExample(texts=['Tansiyon yÃ¼ksekliÄŸi...', 'hipertansiyon...']),
    # ... en az 1000 Ã¶rnek
]

# DataLoader oluÅŸtur
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)

# Contrastive loss ile eÄŸit
train_loss = losses.MultipleNegativesRankingLoss(model)

# Fine-tune
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=5,
    warmup_steps=100
)

# Kaydet
model.save('bge-m3-medical-turkish')
```

#### Senaryo 3: E-ticaret ÃœrÃ¼n Arama

**Gereksinimler:**
- ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e varyasyonlar (tiÅŸÃ¶rt/tshirt, Ã§orap/sok)
- âš¡ Orta hÄ±z
- ğŸ“¦ Ã‡ok fazla Ã¼rÃ¼n

**SeÃ§im:** âœ… **Multi-MiniLM-L12-v2**

**Neden:**
- Morfoloji ÅŸampiyonu (kullanÄ±cÄ±lar farklÄ± yazÄ±yor)
- HÄ±zlÄ±
- KÃ¼Ã§Ã¼k vektÃ¶r = milyonlarca Ã¼rÃ¼n indexlenebilir

#### Senaryo 4: Ã‡ok Dilli Platform (TR + EN + DE)

**Gereksinimler:**
- ğŸŒ Cross-lingual search
- ğŸ”„ Tek model birden fazla dil

**SeÃ§im:** âœ… **BGE-M3**

**Neden:**
- 100+ dil desteÄŸi
- Cross-lingual alignment iyi
- Tek embedding space

---

## ğŸ› ï¸ Kodu Ã‡alÄ±ÅŸtÄ±rma Rehberi

### ğŸ“¦ Kurulum

```bash
# Virtual environment oluÅŸtur
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Paketleri yÃ¼kle
pip install sentence-transformers faiss-cpu scikit-learn pandas torch matplotlib seaborn

# GPU varsa
pip install faiss-gpu  # faiss-cpu yerine
```

### ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```python
# 1. Kodu indir
git clone [repository-url]
cd embedding-comparison

# 2. data.json hazÄ±rla (veya fallback Ã¶rnek veri kullan)
# 3. Ã‡alÄ±ÅŸtÄ±r
python compare_embedding_v2.py

# 4. SonuÃ§lar
# âœ… Terminalde tablo
# âœ… 3 gÃ¶rsel PNG olarak kaydedilir
